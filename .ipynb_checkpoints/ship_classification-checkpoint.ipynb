{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fa09c99d9f5b03e8e3a213f6d84902d5e1d59e1"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a2f9181ed56a8310f6188ac1254f903574fb115",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85e1116d1d675a8ae7fca878c2ddf4469207665d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "TRAIN = '../input/train/'\n",
    "TEST = '../input/test/'\n",
    "SEGMENTATION = '../input/train_ship_segmentations.csv'\n",
    "exclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n",
    "                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n",
    "                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f487dd77687f4edb070bd5d2dc9da9a001d62bdb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nw = 4   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56ed39146115a4767a257fec60a3b367284fa0d6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "for el in exclude_list:\n",
    "    if(el in train_names): train_names.remove(el)\n",
    "    if(el in test_names): test_names.remove(el)\n",
    "#5% of data in the validation set is sufficient for model evaluation\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1085ab7f398dbcde2c28a4476af73f9d04df85e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        if(self.path == TEST): return 0\n",
    "        masks = self.segmentation_df.loc[self.fnames[i]]['EncodedPixels']\n",
    "        if(type(masks) == float): return 0 #NAN - no ship \n",
    "        else: return 1\n",
    "    \n",
    "    def get_c(self): return 2 #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25fa3283c992696575914a5fdb6ebc433a0b5d1f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    #data augmentation\n",
    "    aug_tfms = [RandomRotate(20, tfm_y=TfmType.NO),\n",
    "                RandomDihedral(tfm_y=TfmType.NO),\n",
    "                RandomLighting(0.05, 0.05, tfm_y=TfmType.NO)]\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, \n",
    "                aug_tfms=aug_tfms)\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_n[:-(len(tr_n)%bs)],TRAIN), \n",
    "                (val_n,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    md.is_multi = False\n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "193381699f5595c916647bfd6c51eaeba699379d"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddaf708a2b33a383ccd712d1758718c38eeeb922",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sz = 256 #image size\n",
    "bs = 64  #batch size\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn = ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "149f05054b0fb3dadc126ea2789653603fd4b7ea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "196cf509806bf19556d30514e79e97b41b9b04c1"
   },
   "source": [
    "Training the head part of the model with constant learning rate for one epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef68043848b5d05a0bbc2c53b13dd54767b82f5e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.fit(2e-3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "54961ec96c09672e66ccea9f79c10567dc458df0"
   },
   "source": [
    "Unfreeze the model and train it with differential learning rate. The lr of the head part is still 2e-3, while the middle layers of the model a trained with 5e-4 lr, and the base is trained with even smaller lr, 1e-4, since low level detector do not vary much from one image data set to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33ffa27057b85dd084df994e34874a8a7c131c46",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lr=np.array([1e-4,5e-4,2e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "132c754c6732d8224cbbc60eae835c73ebf4b63e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=2, use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6103281a0c1c7db61fae2743ebcdcddaef9023db"
   },
   "source": [
    "The training has been run with learning rate annealing. Periodic lr increase followed by slow decrease drives the system out of steep minima (when lr is high) towards broader ones (which are explored when lr decreases) that enhances the ability of the model to generalize and reduces overfitting. Due to time limit, only once cycle has been run. But ideally several cycles must be run with gradual increase of the image size, etc. 256x256, 384x384, 768x768, to reach better performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccfd2cf5e8edeceeec185f988ecd4ebd24d14b80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56a469df5b92590a3a5fd4d3015c2f838c307813",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save('Resnet34_lable_256_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5af78f6512ab4f514818ef47b3481ef67a65e46"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4aece9e7181c6eafeba7fa831fa73efeecbd0b8d"
   },
   "outputs": [],
   "source": [
    "log_preds,y = learn.predict_with_targs(is_test=True)\n",
    "probs = np.exp(log_preds)[:,1]\n",
    "pred = (probs > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b50fc52ed7f49e83e79d9ff20cbb2cbf75d3c1bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id':test_names, 'p_ship':probs})\n",
    "df.to_csv('ship_detection.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1eb1634fee993062bc1386da8ce80b54895c60e"
   },
   "source": [
    "### Training on high resolution images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "872e04eaecc268599dab225b43753503ad40910d"
   },
   "source": [
    "Since each epoch on higher resolution images, like 384x384 or 768x768, takes quite long time, training the model from scratch on these images is quite inefficient. Fortunately, modern convolutional nets support input images of arbitrary resolution. To decrease the training time, one can start training the model on low resolution images first and continue training on higher resolution images for only a few epochs. In addition, a model pretrained on low resolution images first generalizes better since a pixel information is less available and high order features are tended to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df8ae8c3b76092761c6eb813a98aca5e22e18c8e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sz = 384 #image size\n",
    "bs = 32  #batch size\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn = ConvLearner.pretrained(arch, md, ps=0.5) #dropout 50%\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.unfreeze()\n",
    "lr=np.array([1e-4,5e-4,2e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee4662b81bbc6d288027850e3ccef5426b72ec66",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('Resnet34_lable_256_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59f3f312fccf272970bafe5d4295094ef6e1af96"
   },
   "source": [
    "Due to the kernal run time limit, the following code does not have enough time to be executed. I hope it is possible to rerun this kernel with disabled cells from \"Model\" part and included data from the previous commit to complete training of higher resolution images. Each epoch on images 383x384 takes about 1.5 hours. Probably, some paths, like \"learn.models_path\", may need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6fffd57bcafceeed806f5d627af53d10a7367b36",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learn.fit(lr/2, 1, cycle_len=2, use_clr=(20,8)) #lr is smaller since bs is only 32\n",
    "#learn.save('Resnet34_lable_384_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
